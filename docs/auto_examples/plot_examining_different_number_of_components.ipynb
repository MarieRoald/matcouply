{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n# Examining effect of adding more components\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\nimport numpy as np\nimport tensorly as tl\n\nimport matcouply.decomposition as decomposition\nfrom matcouply.coupled_matrices import CoupledMatrixFactorization"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Setup\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "I, J, K = 5, 10, 15\nrank = 4\nnoise_level = 0.1\nrng = np.random.default_rng(0)\n\n\ndef truncated_normal(size):\n    x = rng.standard_normal(size=size)\n    x[x < 0] = 0\n    return tl.tensor(x)\n\n\ndef normalize(x):\n    return x / tl.sqrt(tl.sum(x ** 2, axis=0, keepdims=True))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Generate simulated PARFAC2 factor matrices where the true number of components (``rank``) is known\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "A = rng.uniform(size=(I, rank)) + 0.1  # Add 0.1 to ensure that there is signal for all components for all slices\nA = tl.tensor(A)\n\nB_blueprint = truncated_normal(size=(J, rank))\nB_is = [np.roll(B_blueprint, i, axis=0) for i in range(I)]\nB_is = [tl.tensor(B_i) for B_i in B_is]\n\nC = rng.standard_normal(size=(K, rank))\nC = tl.tensor(C)\n\ncmf = CoupledMatrixFactorization((None, (A, B_is, C)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Create data marices from the decomposition and add noise\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "matrices = cmf.to_matrices()\nnoise = [tl.tensor(rng.uniform(size=M.shape)) for M in matrices]\nnoisy_matrices = [M + N * noise_level * tl.norm(M) / tl.norm(N) for M, N in zip(matrices, noise)]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Fit PARAFAC2 models with different number of components to the noisy data\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "fit_scores = []\nB_gaps = []\nA_gaps = []\nfor num_components in range(2, 7):\n    print(num_components, \"components\")\n    lowest_error = float(\"inf\")\n    for init in range(3):  # Here we just do three initialisations, for complex data, you may want to do more\n        cmf, diagnostics = decomposition.parafac2_aoadmm(\n            noisy_matrices,\n            num_components,\n            n_iter_max=1000,\n            non_negative=[True, False, False],\n            return_errors=True,\n            random_state=init,\n        )\n        if diagnostics.regularized_loss[-1] < lowest_error:\n            selected_cmf = cmf\n            selected_diagnostics = diagnostics\n            lowest_error = diagnostics.regularized_loss[-1]\n\n    fit_score = 1 - lowest_error\n    fit_scores.append(fit_score)\n    B_gaps.append(selected_diagnostics.feasibility_gaps[-1][1][0])\n    A_gaps.append(selected_diagnostics.feasibility_gaps[-1][0][0])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Create scree plots of fit score and feasability gaps for different number of components\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "fig, axes = plt.subplots(3, 1, tight_layout=True, sharex=True)\naxes[0].set_title(\"Fit score\")\naxes[0].plot(range(2, 7), fit_scores)\naxes[1].set_title(\"Feasibility gap for A  (NN constraint)\")\naxes[1].plot(range(2, 7), A_gaps)\naxes[2].set_title(\"Feasibility gap for B_is (PF2 constraint)\")\naxes[2].plot(range(2, 7), B_gaps)\naxes[2].set_xlabel(\"No. components\")\naxes[2].set_xticks(range(2, 7))\nplt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The top plot above shows that adding more components improves the fit in the beginning,\nbut then the improvement lessens as we reach the \"true\" number of components.\nWe know that the correct number of components is four for this simulated data,\nbut if you work with a real dataset, you don't always know the \"true\" number.\nSo then, examining such a plot can help you choose an appropriate number of components.\nThe slope of the line plot decreases gradually, so it can be challenging to precisely\ndetermine the correct number of components, but you can make out that 4 and 5 are\ngood candidates. For real data, the line plot might be even more challenging to read,\nand you may find several candidates that you should then examine further.\nNote that the fit score is just one metric and will not give you the entire picture,\nso you should also examine other metrics and, most importantly, look at what makes\nsense for your data when choosing a suitable model.\n\nAnother important metric to consider when evaluating your models is the feasibility gap.\nIf the feasibility gap is too large, then the model doesn't satisfy the constraints. Here,\nwe see that the A-matrix was completely non-negative for all models, while there was a\nslight feasibility gap for the B_i-matrices. This means that the B_i-matrices only\napproximately satisfied the PARAFAC2 constraint (and this will often be the case). The\nfour-component model had the lowest feasibility gap, so it was the model that best followed\nthe PARAFAC2 constraint. This could be a clue that four is an appropriate number of components.\nStill, we see that the feasibility gap was on the order of $10^{-5}$ for all of the\nmodels, which means that the approximation is very good for all of them.\n\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.8"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}